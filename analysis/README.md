# Evaluation pipelines for performance and bias
The two main files are _performance_eval.py_, which evaluates performace, and _bias_eval.py_, which evaluates bias (CrowS-Pairs and StereoSet), for any list of eligible Hugging Face LMs.

To run this code, please install Language Model Evaluation Harness: pip install git+https://github.com/EleutherAI/lm-evaluation-harness.git
