{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "gather": {
     "logged": 1752639993201
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$ python experiments/sentence_debias_subspace.py --model BertModel --model_name_or_path bert-base-uncased --bias_type race --persistent_dir /mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 00:07:16.312222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752710836.332838  137110 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752710836.339132  137110 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752710836.354812  137110 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752710836.354838  137110 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752710836.354840  137110 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752710836.354842  137110 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-17 00:07:16.359396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bias subspace:\n",
      " - persistent_dir: /mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench\n",
      " - model_name_or_path: bert-base-uncased\n",
      " - model: BertModel\n",
      " - bias_type: race\n",
      " - batch_size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding race examples: 100%|██████████| 2621/2621 [25:14<00:00,  1.73it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving computed PCA components to: /mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench/results/subspace/subspace_m-BertModel_c-bert-base-uncased_t-race.pt.\n",
      "\n",
      "$ python experiments/sentence_debias_subspace.py --model BertModel --model_name_or_path bert-base-uncased --bias_type religion --persistent_dir /mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 00:33:52.442725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752712432.464223  141656 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752712432.470599  141656 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752712432.486531  141656 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752712432.486575  141656 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752712432.486577  141656 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752712432.486579  141656 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-17 00:33:52.491233: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bias subspace:\n",
      " - persistent_dir: /mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench\n",
      " - model_name_or_path: bert-base-uncased\n",
      " - model: BertModel\n",
      " - bias_type: religion\n",
      " - batch_size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding religion examples: 100%|██████████| 1235/1235 [11:52<00:00,  1.73it/s]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving computed PCA components to: /mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench/results/subspace/subspace_m-BertModel_c-bert-base-uncased_t-religion.pt.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, re\n",
    "from itertools import product\n",
    "import os\n",
    "repo_root =    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench\" #change for your purpuses\n",
    "\n",
    "models = [\n",
    "    \"bert-base-uncased\", \"babylm/ltgbert-100m-2024\", \"ltg/ltg-bert-babylm\"\n",
    "]\n",
    "bias_types = [\"race\", \"religion\"]\n",
    "\n",
    "batch_size     = 32 \n",
    "persistent_dir = repo_root \n",
    "\n",
    "HF_CLASS = {\n",
    "    r\".*bert.*\"   : \"BertModel\",\n",
    "}\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"PYTHONPATH\"] = f\"{repo_root}:{env.get('PYTHONPATH', '')}\"\n",
    "\n",
    "def get_hf_class(ckpt: str) -> str:\n",
    "    for pat, cls in HF_CLASS.items():\n",
    "        if re.match(pat, ckpt, flags=re.I):\n",
    "            return cls\n",
    "    raise ValueError(f\"No --model mapping defined for {ckpt}\")\n",
    "\n",
    "# --------  launch SentenceDebias sub-space jobs  --------\n",
    "for model_name, bias in product(models, bias_types):\n",
    "    cmd = [\n",
    "        \"python\", \"experiments/sentence_debias_subspace.py\",\n",
    "        \"--model\",             get_hf_class(model_name),\n",
    "        \"--model_name_or_path\", model_name,\n",
    "        \"--bias_type\",          bias,\n",
    "        \"--persistent_dir\",     persistent_dir,\n",
    "    ]\n",
    "    print(\"\\n$ \" + \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True, env=env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1752661366323
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a9f4074a1e4f4db93127790cb605b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bias_direction_religion.pt:   0%|          | 0.00/4.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62164e3932db43c6bf4cb373cfcea06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e39591aa85414991e16798789cb2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  https://huggingface.co/FilipT/bert-base-uncased-sent-debias-religion is ready.\n",
      "   Load with:\n",
      "   from transformers import AutoModelForMaskedLM\n",
      "   m = AutoModelForMaskedLM.from_pretrained('FilipT/bert-base-uncased-sent-debias-religion', trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys, pathlib, textwrap, importlib.util, torch, tempfile, shutil\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from huggingface_hub import HfApi, create_repo, upload_folder\n",
    "\n",
    "HF_TOKEN      = \"hf_XXXXXXX\"\n",
    "HF_REPO       = \"FilipT/bert-base-uncased-sent-debias-religion\"\n",
    "SUBSPACE_PATH = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench/results/subspace/subspace_m-BertModel_c-bert-base-uncased_t-race.pt\"\n",
    "REPO_ROOT     = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench\"\n",
    "\n",
    "MODEL_NAME    = \"bert-base-uncased\"\n",
    "LOCAL_DIR     = pathlib.Path(\"bert-base-uncased-sent-debias-religion\")\n",
    "PROJ_FILENAME = \"bias_direction_religion.pt\"\n",
    "WRAPPER_FILE  = \"modeling_sentence_debias.py\"\n",
    "\n",
    "MODEL_NAME    = \"bert-base-uncased\"\n",
    "PROJ_FILENAME = \"bias_direction_religion.pt\"\n",
    "WRAPPER_FILE  = \"modeling_sentence_debias.py\"\n",
    "\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "from bias_bench.model.models import SentenceDebiasBertForMaskedLM\n",
    "\n",
    "bias_vec = torch.load(SUBSPACE_PATH, map_location=\"cpu\")\n",
    "model    = SentenceDebiasBertForMaskedLM(MODEL_NAME, bias_direction=bias_vec)\n",
    "tok      = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "WRAPPER_CODE = f\"\"\"\n",
    "import torch, transformers, os\n",
    "from functools import partial\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "def _debias_hook(b_dir, module, inputs, output):\n",
    "    x = output.last_hidden_state if hasattr(output, \"last_hidden_state\") else output[0]\n",
    "    b = b_dir.to(x.device)\n",
    "    proj = torch.matmul(x, b) / torch.dot(b, b)\n",
    "    debiased = x - proj.unsqueeze(-1) * b\n",
    "    if hasattr(output, \"last_hidden_state\"):\n",
    "        output.last_hidden_state = debiased\n",
    "        return output\n",
    "    return (debiased,) + output[1:]\n",
    "\n",
    "class SentenceDebiasBertForMaskedLM(transformers.BertForMaskedLM):\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, *args, **kwargs):\n",
    "        model = super().from_pretrained(pretrained_model_name_or_path, *args, **kwargs)\n",
    "        bias_path = kwargs.pop(\"bias_direction_path\", None)\n",
    "        if bias_path is None:\n",
    "            bias_path = hf_hub_download(\n",
    "                repo_id=pretrained_model_name_or_path,\n",
    "                filename=\"{PROJ_FILENAME}\",\n",
    "                revision=kwargs.get(\"revision\", None),\n",
    "            )\n",
    "        bias_vec = torch.load(bias_path, map_location=\"cpu\")\n",
    "        model.bert.register_forward_hook(partial(_debias_hook, bias_vec))\n",
    "        model.register_buffer(\"bias_direction\", bias_vec)\n",
    "        return model\n",
    "\"\"\"\n",
    "\n",
    "tmp = pathlib.Path(tempfile.mkdtemp(prefix=\"sent_debias_\"))\n",
    "(tmp / WRAPPER_FILE).write_text(WRAPPER_CODE, encoding=\"utf-8\")\n",
    "model.save_pretrained(tmp)\n",
    "tok.save_pretrained(tmp)\n",
    "torch.save(bias_vec, tmp / PROJ_FILENAME)\n",
    "\n",
    "cfg = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "cfg.architectures = [\"SentenceDebiasBertForMaskedLM\"]\n",
    "cfg.auto_map = {\n",
    "    \"AutoModelForMaskedLM\": f\"{WRAPPER_FILE[:-3]}.SentenceDebiasBertForMaskedLM\"\n",
    "}\n",
    "cfg.bias_type = \"religion\"\n",
    "cfg.sent_debias_subspace = PROJ_FILENAME\n",
    "cfg.save_pretrained(tmp)\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "create_repo(repo_id=HF_REPO, token=HF_TOKEN, exist_ok=True, repo_type=\"model\")\n",
    "\n",
    "upload_folder(\n",
    "    folder_path=str(tmp),\n",
    "    repo_id=HF_REPO,\n",
    "    token=HF_TOKEN,\n",
    "    commit_message=\"Add religion-debiased bert-base-uncased (Sentence-Debias, standalone)\",\n",
    ")\n",
    "\n",
    "shutil.rmtree(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9659d339fdf84b3095ac6cf3d658413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/393M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7afb6844d6d4887b994a90e18cc9d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bias_direction_religion.pt:   0%|          | 0.00/4.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96869614f9864114a34eaf32afdd47ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  https://huggingface.co/FilipT/ltg-bert-babylm-sd-religion is ready.\n",
      "   from transformers import AutoModelForMaskedLM\n",
      "   m = AutoModelForMaskedLM.from_pretrained('FilipT/ltg-bert-babylm-sd-religion', trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys, pathlib, textwrap, importlib.util, torch, tempfile, shutil\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from huggingface_hub import HfApi, create_repo, upload_folder, hf_hub_download\n",
    "\n",
    "HF_TOKEN      = \"hf_XXXXXXXX\"\n",
    "HF_REPO       = \"FilipT/ltg-bert-babylm-sd-religion\"\n",
    "SUBSPACE_PATH = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench/results/subspace/subspace_m-LtgBertModel_c-ltg-ltg-bert-babylm_t-race.pt\"\n",
    "REPO_ROOT     = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench\"\n",
    "\n",
    "MODEL_NAME    = \"ltg/ltg-bert-babylm\"\n",
    "LOCAL_DIR     = pathlib.Path(\"ltg-bert-babylm-sd-religion\")\n",
    "PROJ_FILENAME = \"bias_direction_religion.pt\"\n",
    "WRAPPER_FILE  = \"modeling_sentence_debias.py\"\n",
    "\n",
    "PROJ_FILENAME = \"bias_direction_religion.pt\"\n",
    "WRAPPER_FILE  = \"modeling_sentence_debias.py\"\n",
    "\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "from bias_bench.model.models import SentenceDebiasLtgBertForMaskedLM\n",
    "\n",
    "bias_vec = torch.load(SUBSPACE_PATH, map_location=\"cpu\")\n",
    "model    = SentenceDebiasLtgBertForMaskedLM(MODEL_NAME, bias_direction=bias_vec)\n",
    "tok      = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "WRAPPER_CODE = f\"\"\"\n",
    "import torch, transformers\n",
    "from functools import partial\n",
    "from huggingface_hub import hf_hub_download\n",
    "from .modeling_ltgbert import LtgBertForMaskedLM\n",
    "\n",
    "def _debias_hook(b_dir, module, inputs, output):\n",
    "    if hasattr(output, \"last_hidden_state\"):\n",
    "        x = output.last_hidden_state\n",
    "        container, key = output, \"last_hidden_state\"\n",
    "    else:\n",
    "        seq = output[0]\n",
    "        if isinstance(seq, list):\n",
    "            x = seq[-1]\n",
    "            container, key = seq, -1\n",
    "        else:\n",
    "            x = seq\n",
    "            container, key = output, 0\n",
    "    b = b_dir.to(x.device)\n",
    "    proj = torch.matmul(x, b) / torch.dot(b, b)\n",
    "    debiased = x - proj.unsqueeze(-1) * b\n",
    "    container[key] = debiased\n",
    "    return output\n",
    "\n",
    "class SentenceDebiasLtgBertForMaskedLM(LtgBertForMaskedLM):\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, *args, **kwargs):\n",
    "        kwargs.setdefault(\"trust_remote_code\", True)\n",
    "        model = super().from_pretrained(pretrained_model_name_or_path, *args, **kwargs)\n",
    "        bias_path = kwargs.pop(\"bias_direction_path\", None)\n",
    "        if bias_path is None:\n",
    "            bias_path = hf_hub_download(\n",
    "                repo_id=pretrained_model_name_or_path,\n",
    "                filename=\"{PROJ_FILENAME}\",\n",
    "                revision=kwargs.get(\"revision\", None),\n",
    "            )\n",
    "        bias_vec = torch.load(bias_path, map_location=\"cpu\")\n",
    "        block = model.transformer if hasattr(model, \"transformer\") else model\n",
    "        block.register_forward_hook(partial(_debias_hook, bias_vec))\n",
    "        model.register_buffer(\"bias_direction\", bias_vec)\n",
    "        return model\n",
    "\"\"\"\n",
    "\n",
    "tmp = pathlib.Path(tempfile.mkdtemp(prefix=\"sent_debias_\"))\n",
    "(tmp / WRAPPER_FILE).write_text(WRAPPER_CODE, encoding=\"utf-8\")\n",
    "\n",
    "for fname in (\"configuration_ltgbert.py\", \"modeling_ltgbert.py\"):\n",
    "    src = hf_hub_download(MODEL_NAME, fname)\n",
    "    shutil.copy(src, tmp / fname)\n",
    "\n",
    "model.save_pretrained(tmp, safe_serialization=False)\n",
    "tok.save_pretrained(tmp)\n",
    "torch.save(bias_vec, tmp / PROJ_FILENAME)\n",
    "\n",
    "cfg = AutoConfig.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "cfg.architectures = [\"SentenceDebiasLtgBertForMaskedLM\"]\n",
    "cfg.auto_map = {\n",
    "    \"AutoConfig\"          : \"configuration_ltgbert.LtgBertConfig\",\n",
    "    \"AutoModelForMaskedLM\": f\"{WRAPPER_FILE[:-3]}.SentenceDebiasLtgBertForMaskedLM\",\n",
    "}\n",
    "cfg.bias_type = \"religion\"\n",
    "cfg.sent_debias_subspace = PROJ_FILENAME\n",
    "cfg.save_pretrained(tmp)\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "create_repo(repo_id=HF_REPO, token=HF_TOKEN, exist_ok=True, repo_type=\"model\")\n",
    "upload_folder(folder_path=str(tmp), repo_id=HF_REPO, token=HF_TOKEN,\n",
    "              commit_message=\"Add religion-debiased LTG-BERT BabyLM (Sentence-Debias)\")\n",
    "shutil.rmtree(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys, pathlib, textwrap, importlib.util, torch, tempfile, shutil\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from huggingface_hub import HfApi, create_repo, upload_folder, hf_hub_download\n",
    "\n",
    "HF_TOKEN      = \"hf_XXXX\"\n",
    "HF_REPO       = \"FilipT/ltg-baseline-babylm-sd-gender\"\n",
    "SUBSPACE_PATH = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench/results/subspace/subspace_m-LtgBertModel_c-babylm-ltgbert-100m-2024_t-race.pt\"\n",
    "REPO_ROOT     = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/test5/code/Users/filip.trhlik/bias-bench\"\n",
    "\n",
    "MODEL_NAME    = \"babylm/ltgbert-100m-2024\"\n",
    "LOCAL_DIR     = pathlib.Path(\"ltg-bert-babylm-sd-gender\")\n",
    "PROJ_FILENAME = \"bias_direction_gender.pt\"\n",
    "WRAPPER_FILE  = \"modeling_sentence_debias.py\"\n",
    "\n",
    "PROJ_FILENAME = \"bias_direction_gender.pt\"\n",
    "WRAPPER_FILE  = \"modeling_sentence_debias.py\"\n",
    "\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "from bias_bench.model.models import SentenceDebiasLtgBertForMaskedLM\n",
    "\n",
    "bias_vec = torch.load(SUBSPACE_PATH, map_location=\"cpu\")\n",
    "model    = SentenceDebiasLtgBertForMaskedLM(MODEL_NAME, bias_direction=bias_vec)\n",
    "tok      = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "WRAPPER_CODE = f\"\"\"\n",
    "import torch, transformers\n",
    "from functools import partial\n",
    "from huggingface_hub import hf_hub_download\n",
    "from .modeling_ltgbert import LtgBertForMaskedLM\n",
    "\n",
    "def _debias_hook(b_dir, module, inputs, output):\n",
    "    if hasattr(output, \"last_hidden_state\"):\n",
    "        x = output.last_hidden_state\n",
    "        container, key = output, \"last_hidden_state\"\n",
    "    else:\n",
    "        seq = output[0]\n",
    "        if isinstance(seq, list):\n",
    "            x = seq[-1]\n",
    "            container, key = seq, -1\n",
    "        else:\n",
    "            x = seq\n",
    "            container, key = output, 0\n",
    "    b = b_dir.to(x.device)\n",
    "    proj = torch.matmul(x, b) / torch.dot(b, b)\n",
    "    debiased = x - proj.unsqueeze(-1) * b\n",
    "    container[key] = debiased\n",
    "    return output\n",
    "\n",
    "class SentenceDebiasLtgBertForMaskedLM(LtgBertForMaskedLM):\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, *args, **kwargs):\n",
    "        kwargs.setdefault(\"trust_remote_code\", True)\n",
    "        model = super().from_pretrained(pretrained_model_name_or_path, *args, **kwargs)\n",
    "        bias_path = kwargs.pop(\"bias_direction_path\", None)\n",
    "        if bias_path is None:\n",
    "            bias_path = hf_hub_download(\n",
    "                repo_id=pretrained_model_name_or_path,\n",
    "                filename=\"{PROJ_FILENAME}\",\n",
    "                revision=kwargs.get(\"revision\", None),\n",
    "            )\n",
    "        bias_vec = torch.load(bias_path, map_location=\"cpu\")\n",
    "        block = model.transformer if hasattr(model, \"transformer\") else model\n",
    "        block.register_forward_hook(partial(_debias_hook, bias_vec))\n",
    "        model.register_buffer(\"bias_direction\", bias_vec)\n",
    "        return model\n",
    "\"\"\"\n",
    "\n",
    "tmp = pathlib.Path(tempfile.mkdtemp(prefix=\"sent_debias_\"))\n",
    "(tmp / WRAPPER_FILE).write_text(WRAPPER_CODE, encoding=\"utf-8\")\n",
    "\n",
    "for fname in (\"configuration_ltgbert.py\", \"modeling_ltgbert.py\"):\n",
    "    src = hf_hub_download(MODEL_NAME, fname)\n",
    "    shutil.copy(src, tmp / fname)\n",
    "\n",
    "model.save_pretrained(tmp, safe_serialization=False)\n",
    "tok.save_pretrained(tmp)\n",
    "torch.save(bias_vec, tmp / PROJ_FILENAME)\n",
    "\n",
    "cfg = AutoConfig.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "cfg.architectures = [\"SentenceDebiasLtgBertForMaskedLM\"]\n",
    "cfg.auto_map = {\n",
    "    \"AutoConfig\"          : \"configuration_ltgbert.LtgBertConfig\",\n",
    "    \"AutoModelForMaskedLM\": f\"{WRAPPER_FILE[:-3]}.SentenceDebiasLtgBertForMaskedLM\",\n",
    "}\n",
    "cfg.bias_type = \"gender\"\n",
    "cfg.sent_debias_subspace = PROJ_FILENAME\n",
    "cfg.save_pretrained(tmp)\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "create_repo(repo_id=HF_REPO, token=HF_TOKEN, exist_ok=True, repo_type=\"model\")\n",
    "upload_folder(folder_path=str(tmp), repo_id=HF_REPO, token=HF_TOKEN,\n",
    "              commit_message=\"Add gender-debiased LTG-BERT BabyLM (Sentence-Debias)\")\n",
    "shutil.rmtree(tmp)\n",
    "\n",
    "print(f\"https://huggingface.co/{HF_REPO} is ready.\\n\"\n",
    "      \"from transformers import AutoModelForMaskedLM\\n\"\n",
    "      f\"m = AutoModelForMaskedLM.from_pretrained('{HF_REPO}', trust_remote_code=True)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
